{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 Part A Traitlets\n",
    "\n",
    "When coding for resource-constrained platforms, it is more effective to separate data capturing and processing into different threads. This tutorial will guide you through using traitlets, a library designed to monitor variable changes. The following code creates a class object and tracks changes to the variable x within that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "# Define a class that inherits from SingletonConfigurable\n",
    "# SingletonConfigurable ensures only one instance of the class exists\n",
    "class Myclass(SingletonConfigurable):\n",
    "    # Declare a variable 'x' that can hold any type of value\n",
    "    x = traitlets.Any()\n",
    "\n",
    "    def __init__(self):\n",
    "        # Call the parent class constructor\n",
    "        super(Myclass, self).__init__()\n",
    "        # Initialize 'x' with a value of 1\n",
    "        self.x = 1\n",
    "\n",
    "# Create a singleton instance of Myclass\n",
    "f = Myclass.instance()\n",
    "\n",
    "# Define a function that will be triggered when 'x' changes\n",
    "def func(change):\n",
    "    print('Value changed to', change['new'])  # Print the new value of 'x'\n",
    "\n",
    "# Observe changes to the 'x' variable and call 'func' when it changes\n",
    "f.observe(func, names=['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to change the f.x value to see what happens\n",
    "f.x=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can improve our previous camera capturing code by separating data display logic from the camera class. By leveraging the traitlets library, we can efficiently monitor changes in the color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import threading\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "# Define a Camera class that inherits from SingletonConfigurable\n",
    "class Camera(SingletonConfigurable):\n",
    "    color_value = traitlets.Any() # monitor the color_value variable\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA #VGA(672*376), HD720(1280*720), HD1080 (1920*1080) or ...\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # Use ULTRA depth mode\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER  # Use meter units (for depth measurements)\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS: #Ensure the camera has opened succesfully\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "         # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width,self.height,sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C4, sl.MEM.CPU) \n",
    "\n",
    "    def _capture_frames(self): #For data capturing only\n",
    "\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                self.color_value= cv2.cvtColor(self.color_value, cv2.COLOR_BGRA2BGR)\n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "                \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera()\n",
    "camera.start() # start capturing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to visualize both color and depth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two widgets for the displaying of the image\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "\n",
    "#create widgets for the displaying of the image\n",
    "display_color = widgets.Image(format='jpeg', width='30%') #determine the width of the color image\n",
    "display_depth = widgets.Image(format='jpeg', width='30%')  #determine the width of the depth image\n",
    "layout=widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth],layout=layout) #horizontal \n",
    "display(sidebyside) #display the widget\n",
    "\n",
    "def func(change):\n",
    "\n",
    "    # sale is necessay for real time data dispalying,\n",
    "    scale = 0.1\n",
    "    resized_image = cv2.resize(change['new'], None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    cv2.circle(resized_image, (int(camera.width*scale//2),int(camera.height*scale//2)), 1, (0, 255, 0))\n",
    "    display_color.value = bgr8_to_jpeg(resized_image)\n",
    "\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(camera.depth_image , alpha=0.03), cv2.COLORMAP_JET)\n",
    "    resized_depth_colormap=cv2.resize(depth_colormap, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    display_depth.value = bgr8_to_jpeg(resized_depth_colormap)\n",
    "\n",
    "camera.observe(func, names=['color_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-26 12:26:35 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-26 12:26:35 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-26 12:26:35 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-26 12:26:36 UTC][ZED][INFO] [Init]  Depth mode: ULTRA\n",
      "[2025-03-26 12:26:37 UTC][ZED][INFO] [Init]  Camera successfully opened.\n",
      "[2025-03-26 12:26:37 UTC][ZED][INFO] [Init]  Camera FW version: 1523\n",
      "[2025-03-26 12:26:37 UTC][ZED][INFO] [Init]  Video mode: HD1080@30\n",
      "[2025-03-26 12:26:37 UTC][ZED][INFO] [Init]  Serial Number: S/N 33902115\n",
      "[2025-03-26 12:26:38 UTC][ZED][WARNING] [Init]  Self-calibration failed. Point the camera towards a more textured and brighter area. Avoid objects closer than 1 meter (Error code: 0x01) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c80e7f8648476c8571819b82425eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='30%'), Image(value=b'', format='jpeg', width='30%')), laâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import threading\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    color_value = traitlets.Any()  # Monitor the color_value variable\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        init_params = sl.InitParameters()\n",
    "        # Set the camera resolution to HD1080 (1920x1080)\n",
    "        init_params.camera_resolution = sl.RESOLUTION.HD1080  # Higher resolution\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS:\n",
    "            print(\"Camera Open : \" + repr(status) + \". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        # Flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width based on the selected resolution\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width, self.height, sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while self.thread_runnning_flag == True:\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                self.color_value = cv2.cvtColor(self.color_value, cv2.COLOR_BGRA2BGR)\n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "    def start(self):\n",
    "        if self.thread_runnning_flag == False:\n",
    "            self.thread_runnning_flag = True\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False\n",
    "            self.thread.join()\n",
    "\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "# Create a camera object\n",
    "camera = Camera()\n",
    "camera.start()  # Start capturing the data\n",
    "\n",
    "# Create widgets for displaying the image\n",
    "display_color = widgets.Image(format='jpeg', width='30%')\n",
    "display_depth = widgets.Image(format='jpeg', width='30%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "def func(change):\n",
    "    # Scale is necessary for real-time data displaying\n",
    "    scale = 0.1\n",
    "    resized_image = cv2.resize(change['new'], None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convert the image to HSV (Hue, Saturation, Value) color space\n",
    "    hsv_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define the range of yellow in HSV space\n",
    "    lower_yellow = np.array([20, 100, 100])  # Lower bound of yellow\n",
    "    upper_yellow = np.array([40, 255, 255])  # Upper bound of yellow\n",
    "    \n",
    "    # Create a mask for yellow color\n",
    "    yellow_mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "    \n",
    "    # Apply the mask to the original image\n",
    "    yellow_image = cv2.bitwise_and(resized_image, resized_image, mask=yellow_mask)\n",
    "\n",
    "    # Display the yellow filtered image\n",
    "    display_color.value = bgr8_to_jpeg(yellow_image)\n",
    "\n",
    "    # Display the depth image as usual\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(camera.depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    resized_depth_colormap = cv2.resize(depth_colormap, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    display_depth.value = bgr8_to_jpeg(resized_depth_colormap)\n",
    "\n",
    "camera.observe(func, names=['color_value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
