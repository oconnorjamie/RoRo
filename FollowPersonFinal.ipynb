{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdd2da-d781-4f19-84be-b03a468f0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Shared data between threads\n",
    "shared_data = {\n",
    "    \"latest_frame\": None,\n",
    "    \"depth_image\": None,\n",
    "    \"frame_id\": 0,\n",
    "    \"jpeg_image\": None,\n",
    "    \"jpeg_depth\": None,\n",
    "}\n",
    "\n",
    "\n",
    "# Data lock\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Constants\n",
    "FRAME_WIDTH = 672\n",
    "IMAGE_CENTER_X = FRAME_WIDTH // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded4af8-143c-4c73-a543-71879de77cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11l_half.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb6148-fb28-4f15-add5-831b8881b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyzed.sl as sl\n",
    "import numpy as np\n",
    "import cv2\n",
    "r\"\"\"\n",
    "class RealCamera:\n",
    "    def __init__(self):\n",
    "        self.zed = sl.Camera()\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA  # 672x376\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS:\n",
    "            print(f\"Failed to open ZED camera: {status}\")\n",
    "            exit(1)\n",
    "\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "        self.image = sl.Mat()\n",
    "        self.depth = sl.Mat()\n",
    "        self.running = False\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        threading.Thread(target=self._capture_loop, daemon=True).start()\n",
    "\n",
    "    def _capture_loop(self):\n",
    "        global shared_data\n",
    "\n",
    "        while self.running:\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "\n",
    "                # Get data in numpy format\n",
    "                color_image = self.image.get_data()\n",
    "                depth_image = self.depth.get_data()\n",
    "\n",
    "                # Convert BGRA to BGR\n",
    "                color_image_bgr = cv2.cvtColor(color_image, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "                with lock:\n",
    "                    shared_data[\"latest_frame\"] = color_image_bgr.copy()\n",
    "                    shared_data[\"depth_image\"] = np.copy(depth_image)\n",
    "                    shared_data[\"frame_id\"] = self.frame_count\n",
    "                    self.frame_count += 1\n",
    "\n",
    "            time.sleep(1 / 30)\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.zed.close()\n",
    "\"\"\"\n",
    "\n",
    "class RealCamera:\n",
    "    def __init__(self):\n",
    "        self.zed = sl.Camera()\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA  # 672x376\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS:\n",
    "            print(f\"Failed to open ZED camera: {status}\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "\n",
    "        self.image = sl.Mat(self.width, self.height, sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "\n",
    "        self.running = False\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        threading.Thread(target=self._capture_loop, daemon=True).start()\n",
    "\n",
    "    def _capture_loop(self):\n",
    "        global shared_data\n",
    "\n",
    "        while self.running:\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "\n",
    "                color_image = self.image.get_data()\n",
    "                color_image_bgr = cv2.cvtColor(color_image, cv2.COLOR_BGRA2BGR)\n",
    "                depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                # Process depth image\n",
    "                depth_image = np.nan_to_num(depth_image, nan=0.0).astype(np.float32)\n",
    "                depth_image[:94, :] = 0\n",
    "                depth_image[282:, :] = 0\n",
    "                depth_image[:, :168] = 0\n",
    "                depth_image[:, 504:] = 0\n",
    "                depth_image[depth_image < 100] = 0\n",
    "                depth_image[depth_image > 1000] = 0\n",
    "\n",
    "                # Create color depth map for display\n",
    "                depth_colormap = cv2.applyColorMap(\n",
    "                    cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET\n",
    "                )\n",
    "\n",
    "                # Resize for display\n",
    "                scale = 0.1\n",
    "                resized_image = cv2.resize(color_image_bgr, None, fx=scale, fy=scale)\n",
    "                resized_depth_colormap = cv2.resize(depth_colormap, None, fx=scale, fy=scale)\n",
    "                cv2.circle(resized_image, (int(self.width*scale//2), int(self.height*scale//2)), 1, (0, 255, 0), -1)\n",
    "\n",
    "                # Encode to JPEG for streaming\n",
    "                jpeg_image = self.bgr8_to_jpeg(resized_image)\n",
    "                jpeg_depth = self.bgr8_to_jpeg(resized_depth_colormap)\n",
    "\n",
    "                # Thread-safe update\n",
    "                with lock:\n",
    "                    shared_data[\"latest_frame\"] = color_image_bgr.copy()\n",
    "                    shared_data[\"depth_image\"] = depth_image.copy()\n",
    "                    shared_data[\"jpeg_image\"] = jpeg_image\n",
    "                    shared_data[\"jpeg_depth\"] = jpeg_depth\n",
    "                    shared_data[\"frame_id\"] = self.frame_count\n",
    "                    self.frame_count += 1\n",
    "\n",
    "            time.sleep(1 / 30)  # 30 FPS\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.zed.close()\n",
    "\n",
    "    def bgr8_to_jpeg(self, value):\n",
    "        return bytes(cv2.imencode('.jpg', value)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927a1b6-de4f-4792-b7bc-b93cf985f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODetector:\n",
    "    def __init__(self, model_path=\"yolo11l_half.engine\", distance_threshold=50, stale_threshold=5):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.running = False\n",
    "        self.next_id = 1  # Counter for assigning new person IDs\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.stale_threshold = stale_threshold\n",
    "\n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        threading.Thread(target=self._detection_loop, daemon=True).start()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "    def _get_center(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "    def _euclidean_distance(self, c1, c2):\n",
    "        return ((c1[0] - c2[0]) ** 2 + (c1[1] - c2[1]) ** 2) ** 0.5\n",
    "\n",
    "    def _detection_loop(self):\n",
    "        while self.running:\n",
    "            frame = None\n",
    "            frame_id = -1\n",
    "\n",
    "            # Get the latest frame\n",
    "            with lock:\n",
    "                if shared_data[\"latest_frame\"] is not None:\n",
    "                    frame = shared_data[\"latest_frame\"].copy()\n",
    "                    frame_id = shared_data[\"frame_id\"]\n",
    "                    current_tracked = shared_data.get(\"tracked_people\", {}).copy()\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            results = self.model(frame, verbose=False)\n",
    "            new_detections = []\n",
    "\n",
    "            # Gather new bounding boxes for people (class 0)\n",
    "            for result in results:\n",
    "                for i, cls_id in enumerate(result.boxes.cls):\n",
    "                    if int(cls_id) == 0:\n",
    "                        bbox = result.boxes.xyxy[i].cpu().numpy()\n",
    "                        new_detections.append(bbox)\n",
    "\n",
    "            updated_people = {}\n",
    "            used_ids = set()\n",
    "\n",
    "            # Match new detections to existing tracked people\n",
    "            for bbox in new_detections:\n",
    "                new_center = self._get_center(bbox)\n",
    "                best_id = None\n",
    "                best_dist = float(\"inf\")\n",
    "\n",
    "                for pid, pdata in current_tracked.items():\n",
    "                    old_center = pdata[\"center\"]\n",
    "                    dist = self._euclidean_distance(new_center, old_center)\n",
    "                    if dist < self.distance_threshold and pid not in used_ids and dist < best_dist:\n",
    "                        best_id = pid\n",
    "                        best_dist = dist\n",
    "\n",
    "                if best_id is not None:\n",
    "                    # Reuse the ID\n",
    "                    updated_people[best_id] = {\n",
    "                        \"bbox\": bbox,\n",
    "                        \"center\": new_center,\n",
    "                        \"last_seen\": frame_id\n",
    "                    }\n",
    "                    used_ids.add(best_id)\n",
    "                else:\n",
    "                    # Assign a new ID\n",
    "                    new_id = self.next_id\n",
    "                    self.next_id += 1\n",
    "                    updated_people[new_id] = {\n",
    "                        \"bbox\": bbox,\n",
    "                        \"center\": new_center,\n",
    "                        \"last_seen\": frame_id\n",
    "                    }\n",
    "                    used_ids.add(new_id)\n",
    "\n",
    "            # Include still-valid unmatched tracked people (not seen in this frame but not too old)\n",
    "            for pid, pdata in current_tracked.items():\n",
    "                if pid not in used_ids:\n",
    "                    if frame_id - pdata[\"last_seen\"] <= self.stale_threshold:\n",
    "                        updated_people[pid] = pdata\n",
    "\n",
    "            # Save updated tracked people to shared data\n",
    "            with lock:\n",
    "                shared_data[\"tracked_people\"] = updated_people\n",
    "\n",
    "            time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cb060-a866-4db3-9a2c-00862d70f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = RealCamera()\n",
    "detector = YOLODetector()\n",
    "\n",
    "camera.start()\n",
    "detector.start()\n",
    "\n",
    "print(\"Camera and detection threads started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e6b83-c43a-4a98-8015-f338684c7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEERING_THRESHOLD = 30  # pixels\n",
    "SAFE_DISTANCE_MM = 400\n",
    "TOO_CLOSE_MM = 380\n",
    "\n",
    "def steering_and_distance_logic_loop(interval=0.2):\n",
    "    while True:\n",
    "        with lock:\n",
    "            frame = shared_data.get(\"latest_frame\")\n",
    "            depth_image = shared_data.get(\"depth_image\")\n",
    "            tracked_people = shared_data.get(\"tracked_people\", {})\n",
    "            selected_id = person_dropdown.value\n",
    "\n",
    "        if selected_id is not None and frame is not None and depth_image is not None:\n",
    "            person_data = tracked_people.get(int(selected_id))\n",
    "            if person_data:\n",
    "                x1, y1, x2, y2 = map(int, person_data[\"bbox\"])\n",
    "                cx = (x1 + x2) // 2\n",
    "                cy = (y1 + y2) // 2\n",
    "\n",
    "                delta = cx - IMAGE_CENTER_X\n",
    "\n",
    "                if abs(delta) >= STEERING_THRESHOLD:\n",
    "                    direction = \"LEFT\" if delta < 0 else \"RIGHT\"\n",
    "                    print(f\"[{selected_id}] STEER {direction}\")\n",
    "                else:\n",
    "                    # Person is centered — now check distance\n",
    "                    if 0 <= cy < depth_image.shape[0] and 0 <= cx < depth_image.shape[1]:\n",
    "                        #window = depth_image[max(0, cy - 1):cy + 2, max(0, cx - 1):cx + 2]\n",
    "                        #valid_depths = window[~np.isnan(window) & (window > 0)]\n",
    "                        #if valid_depths.size > 0:\n",
    "                        #    depth_val = np.median(valid_depths)\n",
    "                        #    if depth_val > SAFE_DISTANCE_MM:\n",
    "                        #        print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — MOVE FORWARD \")\n",
    "                        #    elif depth_val < TOO_CLOSE_MM:\n",
    "                        #        print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — MOVE BACKWARD \")\n",
    "                        #    else:\n",
    "                        #        print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — HOLD POSITION \")\n",
    "                        #else:\n",
    "                        #    print(f\"[{selected_id}]  CENTERED |  No valid depth in 3x3 region\")\n",
    "                        depth_val = depth_image[cy, cx]\n",
    "                        if not np.isnan(depth_val) and depth_val > 0:\n",
    "                            if depth_val > SAFE_DISTANCE_MM:\n",
    "                                print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — MOVE FORWARD \")\n",
    "                            elif depth_val < TOO_CLOSE_MM:\n",
    "                                print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — MOVE BACKWARD \")\n",
    "                            else:\n",
    "                                print(f\"[{selected_id}]  CENTERED | {depth_val:.1f} mm — HOLD POSITION \")\n",
    "                        else:\n",
    "                            print(f\"[{selected_id}]  CENTERED |  Depth data unavailable\")\n",
    "                    else:\n",
    "                        print(f\"[{selected_id}]  CENTERED |  Invalid coordinates (cx={cx}, cy={cy})\")\n",
    "        time.sleep(interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c3562-d7f2-40fe-af4b-79b09d6e48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# --- UI Setup ---\n",
    "display_widget = widgets.Image(format='jpeg', width=600)\n",
    "person_dropdown = widgets.Dropdown(options=[], description=\"Person ID:\")\n",
    "\n",
    "display(widgets.VBox([display_widget, person_dropdown]))\n",
    "\n",
    "# --- Utility ---\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "# --- Display Update Function ---\n",
    "def update_display():\n",
    "    with lock:\n",
    "        frame = shared_data.get(\"latest_frame\")\n",
    "        frame_id = shared_data.get(\"frame_id\", -1)\n",
    "        tracked_people = shared_data.get(\"tracked_people\", {})\n",
    "\n",
    "    if frame is None:\n",
    "        return\n",
    "\n",
    "    display_frame = frame.copy()\n",
    "    selected_id = str(person_dropdown.value)\n",
    "\n",
    "    # Update dropdown options if people change\n",
    "    current_ids = sorted(map(str, tracked_people.keys()))\n",
    "    if person_dropdown.options != current_ids:\n",
    "        person_dropdown.options = current_ids\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for pid, pdata in tracked_people.items():\n",
    "        x1, y1, x2, y2 = map(int, pdata[\"bbox\"])\n",
    "        color = (0, 255, 0) if str(pid) == selected_id else (255, 0, 0)\n",
    "        label = f\"ID {pid}\"\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(display_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    #resized = cv2.resize(display_frame, None, fx=0.5, fy=0.5)\n",
    "    #display_widget.value = bgr8_to_jpeg(resized)\n",
    "    with lock:\n",
    "        jpeg_image = shared_data.get(\"jpeg_image\")\n",
    "    \n",
    "    if jpeg_image:\n",
    "        display_widget.value = jpeg_image\n",
    "\n",
    "# --- Periodic Update Loop ---\n",
    "def schedule_update(interval=0.1):\n",
    "    def loop():\n",
    "        while True:\n",
    "            update_display()\n",
    "            time.sleep(interval)\n",
    "\n",
    "    threading.Thread(target=loop, daemon=True).start()\n",
    "\n",
    "# --- Start the Update Loop ---\n",
    "schedule_update()\n",
    "threading.Thread(target=steering_and_distance_logic_loop, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caaa1a0-12ad-4ac8-b070-570c21749fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()\n",
    "detector.stop()\n",
    "\n",
    "print(\"Camera and detection threads stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48965c04-dc9c-4d34-99f7-e93b31baa04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
